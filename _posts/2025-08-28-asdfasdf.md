---
title: "asdfasdf"
date: 2025-08-28 17:37:30 +0900
categories: [요리]
tags: [Python, RAG]
toc: true
comments: false
mermaid: true
math: true
---

# RAG 시대의 핵심 구성요소와 LangChain으로 보는 실무 흐름

현대 대화형 AI의 큰 흐름은 외부 지식과의 연결, 즉 RAG(retrieval-augmented generation)입니다. 문서를 임베딩하고 벡터 저장소에서 필요 시 검색해 LM의 응답에 근거를 제공합니다. 핵심 구성요소를 정리합니다.

- Document loader: 다양한 소스의 문서를 수집하고 표준 형식으로 변환합니다.
- Embedding model: CLIP 등으로 텍스트/멀티모달 임베딩을 만들어 벡터를 생성합니다.
- Vectorstore: 생성된 벡터를 저장하고 효율적으로 조회합니다.
- Retriever: 벡터 검색으로 관련 문서를 선정합니다.
- LM: 최종 응답을 생성하는 언어 모델입니다.
- Memory: 대화 맥락과 상태를 유지해 일관된 흐름을 돕습니다.
- Chain: 질의 → 검색 → 생성의 흐름을 하나의 파이프라인으로 엮습니다.
- Agent/Tool: 에이전트가 필요 시 외부 도구를 호출하도록 합니다.
- Graph/LangGraph: 파이프라인과 데이터 흐름을 그래프 형태로 관리합니다.
- 실행 환경: Ollama로 로컬에서 LM을 구동하거나 PART, LangGraph로 확장을 쉽게 할 수 있습니다.

결론 요약: RAG의 핵심은 외부 지식과의 연결, 임베딩/저장소의 효율, 그리고 LangChain의 체인과 그래프로 구성한 명확한 흐름입니다. 필요에 따라 로컬 실행과 확장을 적용해 실무에 맞춘 지식기반 대화를 설계하세요.